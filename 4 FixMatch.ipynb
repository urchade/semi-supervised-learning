{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_stats = dict(mean=[0.4914, 0.4822, 0.4465],\n",
    "                     std=[0.2470,  0.2435,  0.2616])\n",
    "\n",
    "# see the paper for the proper augmentation\n",
    "transform_weak = transforms.Compose([\n",
    "    transforms.RandomCrop(size=32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(**channel_stats),\n",
    "])\n",
    "\n",
    "transform_strong = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=32),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(hue=[-0.1, 0.1]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(**channel_stats),\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(**channel_stats),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load cifar 10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "\n",
    "supervised, unsupervised = random_split(train, [10000, 40000])\n",
    "\n",
    "val = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(data, transform):\n",
    "    \n",
    "    x, y = data\n",
    "    \n",
    "    mean = torch.Tensor(channel_stats['std']).view(-1, 1, 1)\n",
    "    \n",
    "    std = torch.Tensor(channel_stats['mean']).view(-1, 1, 1)\n",
    "    \n",
    "    de_normalized = transform(x) * std + mean\n",
    "        \n",
    "    plt.imshow(de_normalized.permute(1, 2, 0))\n",
    "    \n",
    "    plt.title(train.classes[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(train[100], transform_strong)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemiData(Dataset):\n",
    "    \n",
    "    def __init__(self, data, supervised = True):\n",
    "        \n",
    "        self.data = data\n",
    "        \n",
    "        self.supervised = supervised\n",
    "        \n",
    "    def __len__(self): return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        x, y = self.data[idx]\n",
    "        \n",
    "        x1 = transform_weak(x)\n",
    "        x2 = transform_strong(x)\n",
    "        \n",
    "        if self.supervised:\n",
    "            return x1, y\n",
    "        else:\n",
    "            return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_batch_size = 128\n",
    "mu = 4\n",
    "\n",
    "sup_loader = DataLoader(SemiData(supervised, supervised=True), batch_size=sup_batch_size, shuffle=True, num_workers=15)\n",
    "\n",
    "unsup_loader = DataLoader(SemiData(unsupervised, supervised=False), batch_size=sup_batch_size * mu, shuffle=True, num_workers=15)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size=100, shuffle=False, num_workers=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see Notebook **013 - Convolution Layer.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$O = (I âˆ’ K + 2 P)/S+1$\n",
    "\n",
    "- O : output size\n",
    "- I : input size\n",
    "- K : kernel size\n",
    "- P : padding\n",
    "- S : stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fe = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1), # (32 - 3 + 2 * 0)/1 + 1 = 30\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1), # (30 - 3 + 2 * 0)/1 + 1 = 28\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2), # (28 - 4 + 2 * 0)/2 + 1 = 13\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2), # (13 - 3 + 2 * 0)/2 + 1 = 6\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),  # (6 - 2)/2 + 1 = 3\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(128 * 3 * 3, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # x of size [batch_size, 3, W, H]\n",
    "        \n",
    "        h = self.fe(x) # [batch_size, 128, 3, 3]\n",
    "                \n",
    "        h = h.view(-1, 128 * 3 * 3)\n",
    "        \n",
    "        return self.fc(h) # [batch_size, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fixMatch(model: nn.Module,\n",
    "                    opt: torch.optim,\n",
    "                    sup_loader: torch.utils.data.DataLoader,\n",
    "                    unsup_loader: torch.utils.data.DataLoader,\n",
    "                    tau: float=0.95,\n",
    "                    alpha: float=0.5):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        device = param.device\n",
    "        break\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    pbar = tqdm(sup_loader)\n",
    "    \n",
    "    unsup_iter = iter(unsup_loader)\n",
    "    \n",
    "    for batch_sup in pbar:\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        # labelled data\n",
    "        x_sup, y = batch_sup\n",
    "        x_sup, y = x_sup.to(device), y.to(device)\n",
    "        \n",
    "        # unlabelled data\n",
    "        try:\n",
    "            x_weak, x_strong = next(unsup_iter)\n",
    "        except StopIteration:\n",
    "            unsup_iter = iter(unsup_loader)\n",
    "            x_weak, x_strong = next(unsup_iter)\n",
    "                \n",
    "        x_weak, x_strong = x_weak.to(device), x_strong.to(device)\n",
    "        \n",
    "        # concat all x\n",
    "        all_x = torch.cat([x_sup, x_weak, x_strong], dim=0)\n",
    "        \n",
    "        # compute logits\n",
    "        all_logits = model(all_x)\n",
    "        \n",
    "        # logits and loss for labelled data\n",
    "        logits_sup = all_logits[:x_sup.size(0)]\n",
    "        loss_sup = F.cross_entropy(logits_sup, y)\n",
    "        \n",
    "        # logits for unlabelled data\n",
    "        logits_unsup = all_logits[x_sup.size(0):]\n",
    "        logits_weak, logits_strong = torch.chunk(logits_unsup, 2, dim=0)\n",
    "        \n",
    "        # stop gradient for weak augmented\n",
    "        logits_weak = logits_weak.detach() \n",
    "        \n",
    "        # compute class probailities\n",
    "        probs_weak = F.softmax(logits_weak, dim=1)\n",
    "        \n",
    "        # compute pseudo labels (torch.max outputs the maximum values and the argmax)\n",
    "        max_prob, pseudo_label = torch.max(probs_weak, dim=1)\n",
    "        \n",
    "        # [batch,]\n",
    "        \n",
    "        # mask for\n",
    "        mask = (max_prob > tau).float() # [1, 0] [batch_size,]\n",
    "                \n",
    "        # mask non-confident prediction\n",
    "        pseudo_label = pseudo_label.masked_fill(mask == 0, -1) # [3, -1, ...]\n",
    "        \n",
    "        # unsupervised loss by ignoring non-confident prediction\n",
    "        loss_unsup = F.cross_entropy(logits_strong, pseudo_label, ignore_index=-1)\n",
    "        \n",
    "        # total loss\n",
    "        loss = loss_sup + alpha * loss_unsup\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        opt.step()\n",
    "        \n",
    "        loss_item = loss.item()\n",
    "        \n",
    "        losses.append(loss_item)\n",
    "        \n",
    "        pbar.set_description(f'train_loss = {np.array(losses).mean(): .3f}')\n",
    "        \n",
    "    return np.array(losses).mean()\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model: nn.Module, dataloader: torch.utils.data.DataLoader):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        device = param.device\n",
    "        break\n",
    "     \n",
    "    labels_all = []\n",
    "    logits_all = []\n",
    "    \n",
    "    for x, y in dataloader:\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        logits = model(x)\n",
    "        \n",
    "        labels_all += y.cpu().numpy().tolist()\n",
    "        logits_all += logits.cpu().numpy().tolist()\n",
    "        \n",
    "    prediction = np.argmax(np.array(logits_all), axis=-1)\n",
    "    \n",
    "    acc = accuracy_score(labels_all, prediction)\n",
    "                    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "\n",
    "model = ConvNet().cuda()\n",
    "\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b59870ff0d949a79ce4f45d3aebef1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(3., device='cuda:0')\n",
      "tensor(14., device='cuda:0')\n",
      "tensor(19., device='cuda:0')\n",
      "tensor(24., device='cuda:0')\n",
      "tensor(20., device='cuda:0')\n",
      "tensor(13., device='cuda:0')\n",
      "tensor(6., device='cuda:0')\n",
      "tensor(8., device='cuda:0')\n",
      "tensor(3., device='cuda:0')\n",
      "tensor(6., device='cuda:0')\n",
      "tensor(6., device='cuda:0')\n",
      "tensor(7., device='cuda:0')\n",
      "tensor(10., device='cuda:0')\n",
      "tensor(10., device='cuda:0')\n",
      "tensor(8., device='cuda:0')\n",
      "tensor(16., device='cuda:0')\n",
      "tensor(14., device='cuda:0')\n",
      "tensor(10., device='cuda:0')\n",
      "tensor(12., device='cuda:0')\n",
      "tensor(7., device='cuda:0')\n",
      "tensor(9., device='cuda:0')\n",
      "tensor(7., device='cuda:0')\n",
      "tensor(7., device='cuda:0')\n",
      "tensor(6., device='cuda:0')\n",
      "tensor(9., device='cuda:0')\n",
      "tensor(2., device='cuda:0')\n",
      "tensor(8., device='cuda:0')\n",
      "tensor(7., device='cuda:0')\n",
      "tensor(8., device='cuda:0')\n",
      "tensor(8., device='cuda:0')\n",
      "tensor(6., device='cuda:0')\n",
      "tensor(9., device='cuda:0')\n",
      "tensor(7., device='cuda:0')\n",
      "tensor(9., device='cuda:0')\n",
      "tensor(9., device='cuda:0')\n",
      "tensor(15., device='cuda:0')\n",
      "tensor(14., device='cuda:0')\n",
      "tensor(14., device='cuda:0')\n",
      "tensor(15., device='cuda:0')\n",
      "tensor(8., device='cuda:0')\n",
      "tensor(9., device='cuda:0')\n",
      "tensor(7., device='cuda:0')\n",
      "tensor(2., device='cuda:0')\n",
      "tensor(3., device='cuda:0')\n",
      "tensor(7., device='cuda:0')\n",
      "tensor(5., device='cuda:0')\n",
      "tensor(2., device='cuda:0')\n",
      "tensor(4., device='cuda:0')\n",
      "tensor(6., device='cuda:0')\n",
      "tensor(9., device='cuda:0')\n",
      "tensor(12., device='cuda:0')\n",
      "tensor(11., device='cuda:0')\n",
      "tensor(10., device='cuda:0')\n",
      "tensor(8., device='cuda:0')\n",
      "tensor(12., device='cuda:0')\n",
      "tensor(9., device='cuda:0')\n",
      "tensor(5., device='cuda:0')\n",
      "tensor(9., device='cuda:0')\n",
      "tensor(4., device='cuda:0')\n",
      "tensor(7., device='cuda:0')\n",
      "tensor(10., device='cuda:0')\n",
      "tensor(17., device='cuda:0')\n",
      "tensor(17., device='cuda:0')\n",
      "tensor(17., device='cuda:0')\n",
      "tensor(20., device='cuda:0')\n",
      "tensor(18., device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b978c9a8b06a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_fixMatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msup_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsup_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-fa735323e5a6>\u001b[0m in \u001b[0;36mtrain_fixMatch\u001b[0;34m(model, opt, sup_loader, unsup_loader, tau, alpha)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m# mask non-confident prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mpseudo_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpseudo_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [3, -1, ...]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# unsupervised loss by ignoring non-confident prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for t in range(5):\n",
    "    train_fixMatch(model, opt, sup_loader, unsup_loader, tau=0.9, alpha=0.3)\n",
    "    val_acc = validate(model, val_loader)\n",
    "    print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_UZA",
   "language": "python",
   "name": "py37_uza"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
